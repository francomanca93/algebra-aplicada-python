<div align="center">
    <h1>Álgebra Lineal Aplicada para Machine Learning</h1>
    <img src="https://imgur.com/xlE7Ayu.png" width="">
</div>

## Tabla de contenidos

- [Transformaciones lineales y descomposición de matrices](#transformaciones-lineales-y-descomposición-de-matrices)
  - [Introducción al curso](#introducción-al-curso)
- [Aplicaciones de SVD a una imagen](#aplicaciones-de-svd-a-una-imagen)
- [Aplicando Álgebra Lineal: Análisis de Componentes Principales (PCA)](#aplicando-álgebra-lineal-análisis-de-componentes-principales-pca)

# Transformaciones lineales y descomposición de matrices

## Introducción al curso

En el curso anterior de [Fundamentos de Algebra Lineal con Python](https://github.com/francomanca93/fundamentos-algebra-lineal) vimos:

- Que es una Matriz.
- Que operaciones puedo realizar con ellas.
- Que es una matriz identidad.
- El calculo de la inversa de una matriz cuadrada.

Ahora con esas bases vamos a poder calcular y aprender:

- ¿Qué son los auto valores?
- ¿Qué son los auto vectores?
- ¿Cómo puedo mediante esto descomponer una matriz?
- Si descompongo una matriz, siempre es única esa descomposición.
- ¿Qué es la descomposición en valores singulares?
- ¿Cómo calcular una pseudoinversa?

Por qué todo esto es tan importante:

Debido a que en Machine Learning debemos tener cuidado en los tiempos computacionales, si no somos cuidadosos y reducimos la cantidad de dimensiones que estamos entregando vamos a necesitar grades volúmenes de datos que hagan que nuestros procesos demoren muchísimo mas tiempo.

Ahora, antes de empezar: ¿Por qué a la matrices las pensamos como transformaciones lineales?

# Aplicaciones de SVD a una imagen

# Aplicando Álgebra Lineal: Análisis de Componentes Principales (PCA)
